{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd0879161f803c394d91faf747ff6d3a2fcf4488382d4a4886d22ca9f87a5fa9217",
   "display_name": "Python 3.8.0  ('bjf': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "879161f803c394d91faf747ff6d3a2fcf4488382d4a4886d22ca9f87a5fa9217"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Explore kaggle data and combine to a single dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Run the following notebook to build a combined dataset that will be used for training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"../data/raw/data_scientist_united_states_job_postings_jobspikr.csv\")\n",
    "df2 = pd.read_csv(\"../data/raw/data/Uncleaned_DS_jobs.csv\")\n",
    "df3 = pd.read_csv(\"../data/raw/data/DataScientist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"job_board\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.head())\n",
    "print(df1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2.head())\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df3.head())\n",
    "print(df3.shape)"
   ]
  },
  {
   "source": [
    "Looking at the shape of each of the data sources, we expect the total number of job posts in the combined dataset to be close to 14581."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows total number of missing values for each column\n",
    "print(df1.isna().sum())\n",
    "print(df2.isna().sum())\n",
    "print(df3.isna().sum())"
   ]
  },
  {
   "source": [
    "Looking at the head of the data we see quite a few missing values. We see that in df1, 9 columns contain many missing values. However, this is ok because the columns we are interested in are mainly job_title, company name, and job description. These columns contain almost no missing values which is good."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 1 row where company name is missing\n",
    "df1 = df1.dropna(subset=[\"company_name\"])\n",
    "df1 = df1.fillna(\"Unknown\")\n",
    "print(df1.shape)"
   ]
  },
  {
   "source": [
    "Now lets clean up the company name column for df2 and df3, since it looks as if the rating is attached to the end of the company name."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the company name by removing the rating attached to the end\n",
    "df2[\"Company Name\"] = df2[\"Company Name\"].apply(lambda x: x.split('\\n')[0])\n",
    "df3[\"Company Name\"] = df3[\"Company Name\"].apply(lambda x: x.split('\\n')[0])\n",
    "\n",
    "print(df2[\"Company Name\"])\n",
    "print(df3[\"Company Name\"])"
   ]
  },
  {
   "source": [
    "Now we can combine the 3 data sources by job title, company name, job description"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the columns we want\n",
    "subset1 = df1[[\"job_title\",\"company_name\",\"job_description\",\"job_board\"]]\n",
    "subset1.columns = [\"Job Title\", \"Company Name\",\"Job Description\",\"Job Board\"]\n",
    "\n",
    "subset2 = df2[[\"Job Title\", \"Company Name\",\"Job Description\"]]\n",
    "subset2[\"Job Board\"] = \"Glassdoor\"\n",
    "subset3 = df3[[\"Job Title\", \"Company Name\",\"Job Description\"]]\n",
    "subset3[\"Job Board\"] = \"Glassdoor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all 3 data sources\n",
    "combined_dataset = pd.concat([subset1,subset2,subset3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset.shape"
   ]
  },
  {
   "source": [
    "The shape of the combined dataset matches what we expect to have. So in total we have 14580 data science related job postings."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Let's see the distribution of where the different job posts came from"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_dataset[\"Job Board\"].value_counts().plot(kind='pie',figsize=(15,15),autopct='%1.1f%%')"
   ]
  },
  {
   "source": [
    "Indeed and Glassdoor make up a major of this dataset. This will be important later on in testing so we can properly split the data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We have build a combined dataset that will be used for training."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Explore the Job Descriptions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pick a random job post\n",
    "# check out 30,\n",
    "num = 25\n",
    "job_description = combined_dataset[\"Job Description\"][num].values[0]\n",
    "job_title = combined_dataset[\"Job Title\"][num].values[0]\n",
    "print(job_title)\n",
    "print(job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the word count for each job description\n",
    "combined_dataset['Count'] = combined_dataset['Job Description'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show descriptive statistics abouth the word count\n",
    "print(\"Descriptive statistics\")\n",
    "print(f\"Min length: {combined_dataset['Count'].describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_dataset['Job Description'][combined_dataset[\"Count\"] == combined_dataset[\"Count\"].min()])\n",
    "print(combined_dataset['Job Description'][combined_dataset[\"Count\"] == combined_dataset[\"Count\"].max()])"
   ]
  },
  {
   "source": [
    "By finding the word count for each of the job descriptions we can better understand how long job description's usually are. The data contains rows where the job description is 2 words, and the longest is 4764 words."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset[\"Count\"].plot.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset.boxplot(column=[\"Count\"])"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}